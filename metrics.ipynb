{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 14:54:11.408131: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Classification with abstention metric classes and functions.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "__author__ = \"Elizabeth A. Barnes and Randal J. Barnes\"\n",
    "__date__ = \"January 11, 2021\"\n",
    "\n",
    "# np.warnings.filterwarnings('ignore', category=np.VisibleDeprectionWarning)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# FUNCTIONS\n",
    "#\n",
    "#   The following metric functions are used for comparison purposes and\n",
    "#   plotting.  These are not necessarily tensorflow compliant.\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def compute_dnn_accuracy(y_true, y_pred, perc, tranquil=np.nan):\n",
    "    \"\"\"Compute the categorical accuracy for the predictions above the\n",
    "    percentile threshold.\"\"\"\n",
    "    max_logits = np.max(y_pred, axis=-1)\n",
    "    i = np.where(max_logits >= np.percentile(max_logits, 100 - perc))[0]\n",
    "    met = tf.keras.metrics.CategoricalAccuracy()\n",
    "    met.update_state(y_true[i, :], y_pred[i, :])\n",
    "    return met.result().numpy()\n",
    "\n",
    "\n",
    "def compute_dac_accuracy(y_true, y_pred, abstain):\n",
    "    \"\"\"Compute the categorical accuracy the predictions excluding abstentions.\"\"\"\n",
    "    cat_pred = tf.math.argmax(y_pred, axis=-1)\n",
    "    mask = tf.math.not_equal(cat_pred, abstain)\n",
    "    met = tf.keras.metrics.CategoricalAccuracy()\n",
    "    met.update_state(tf.boolean_mask(y_true, mask), tf.boolean_mask(y_pred, mask))\n",
    "    return met.result().numpy()\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# CLASSES\n",
    "#\n",
    "#   The following metrics classes are tensorflow compliant.\n",
    "#\n",
    "#   See page 390 of Geron, 2019, for a prototype of a metric class. See also,\n",
    "#   https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Metric.\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "class PredictionAccuracy(tf.keras.metrics.Metric):\n",
    "    \"\"\"Compute the prediction accuracy for an epoch.\n",
    "\n",
    "    The prediction accuracy does not include abstentions. The prediction\n",
    "    accuracy is the total number of correct predictions divided by the\n",
    "    total number of predictions, across the entire epoch. This is not the\n",
    "    same as the average of batch prediction accuracies.\n",
    "\n",
    "    The computation is done by maintaining running sums of total predictions\n",
    "    and correct predictions made across all batches in an epoch. The running\n",
    "    sums are reset at the end of each epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, abstain, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.abstain = abstain\n",
    "        self.correct = self.add_weight(\"correct\", initializer=\"zeros\")\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        cat_pred = tf.math.argmax(y_pred, axis=-1)\n",
    "        cat_true = tf.math.argmax(y_true, axis=-1)\n",
    "\n",
    "        mask = tf.math.not_equal(cat_pred, self.abstain)\n",
    "        cat_pred = tf.boolean_mask(cat_pred, mask)\n",
    "        cat_true = tf.boolean_mask(cat_true, mask)\n",
    "\n",
    "        batch_correct = tf.math.count_nonzero(tf.math.equal(cat_pred, cat_true))\n",
    "        batch_total = tf.math.count_nonzero(mask)\n",
    "\n",
    "        self.correct.assign_add(tf.cast(batch_correct, tf.float32))\n",
    "        self.total.assign_add(tf.cast(batch_total, tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.correct / self.total\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return{**base_config}\n",
    "\n",
    "\n",
    "class PredictionLoss(tf.keras.metrics.Metric):\n",
    "    \"\"\"Compute the prediction loss for epoch.\n",
    "\n",
    "    The prediction loss does not include abstentions. Thus, the loss is the\n",
    "    sample-by-sample cross entropy.\n",
    "\n",
    "    The prediction loss is the sum predictions losses divided by the total\n",
    "    number of predictions, across the entire epoch. This is not the same as\n",
    "    the average of batch prediction losses.\n",
    "\n",
    "    The computation is done by maintaining running sums of prediction losses\n",
    "    prediction counts, across the entire epoch. The running sums are reset at\n",
    "    the end of each epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, abstain, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.abstain = abstain\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        predicted = tf.math.argmax(y_pred, axis=-1)\n",
    "\n",
    "        q = 1 - y_pred[:, -1]\n",
    "        logq = tf.math.log(q)\n",
    "\n",
    "        r = tf.boolean_mask(y_pred, y_true)\n",
    "        logr = tf.math.log(r)\n",
    "\n",
    "        mask = tf.math.not_equal(predicted, self.abstain)\n",
    "        loss = tf.boolean_mask(logq - logr, mask)\n",
    "\n",
    "        batch_count = tf.math.count_nonzero(mask)\n",
    "        batch_total = tf.math.reduce_sum(loss)\n",
    "\n",
    "        self.count.assign_add(tf.cast(batch_count, tf.float32))\n",
    "        self.total.assign_add(tf.cast(batch_total, tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.total / float(self.count)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return{**base_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threat_score(true_pos, false_pos, false_neg):\n",
    "    \"\"\"\n",
    "    Compute the threat score (Critical Success Index or POD).\n",
    "\n",
    "    Args:\n",
    "    true_pos (int): Number of true positives.\n",
    "    false_pos (int): Number of false positives.\n",
    "    false_neg (int): Number of false negatives.\n",
    "\n",
    "    Returns:\n",
    "    float: Threat score value between 0 and 1. Higher values indicate better prediction accuracy.\n",
    "    \"\"\"\n",
    "    denominator = true_pos + false_pos + false_neg\n",
    "    if denominator == 0:\n",
    "        return 0.0  # Handle the case where there are no events in the ground truth\n",
    "    \n",
    "    return true_pos / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gilbert_skill_score(true_pos, false_pos, false_neg, chance_hit):\n",
    "    \"\"\"\n",
    "    Compute the Gilbert Skill score. Incorporates number of hits due to random chance. A skill corrected verification measure of categorical forecast performance similar \n",
    "    to the critical success index (CSI) but which takes into account the number of hits due to chance.\n",
    "\n",
    "    Args:\n",
    "    true_pos (int): Number of true positives.\n",
    "    false_pos (int): Number of false positives.\n",
    "    false_neg (int): Number of false negatives.\n",
    "    chance_hit : Number of correct hits due to purely random chance; CH= (A+B)(A+C)/n\n",
    "\n",
    "    Returns:\n",
    "    float: Threat score value between 0 and 1. Higher values indicate better prediction accuracy.\n",
    "    \n",
    "    Formula: GS= (A-CH)/(A+B+C-CH)\n",
    "    \"\"\"\n",
    "    numerator = true_pos - chance_hit\n",
    "    denominator = true_pos + false_pos + false_neg - chance_hit\n",
    "    if denominator == 0:\n",
    "        return 0.0  # Handle the case where there are no events in the ground truth\n",
    "    \n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(predclasses, targclasses):\n",
    "\n",
    "    class_names = np.unique(targclasses)\n",
    "\n",
    "    table = []\n",
    "    for pred_class in class_names:\n",
    "        row = []\n",
    "        for true_class in class_names:\n",
    "            row.append(100 * np.mean(predclasses[targclasses == true_class] == pred_class))\n",
    "        table.append(row)\n",
    "    class_titles_t = [\"T(Light)\", \"T(Heavy)\"]\n",
    "    class_titles_p = [\"P(Light)\", \"P(Heavy)\"]\n",
    "    conf_matrix = pd.DataFrame(table, index=class_titles_p, columns=class_titles_t)\n",
    "    display(conf_matrix.style.background_gradient(cmap='Blues').format(\"{:.1f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
