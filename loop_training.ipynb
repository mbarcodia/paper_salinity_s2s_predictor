{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: marcodia\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import random\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "import import_ipynb\n",
    "import sys\n",
    "import os \n",
    "\n",
    "import network_arch as network\n",
    "import metrics\n",
    "import plot\n",
    "import settings \n",
    "import functions_misc as fnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MAKE THE NN ARCHITECTURE\n",
    "def make_model():\n",
    "    # Define and train the model\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = network.defineNN(HIDDENS,\n",
    "                             input1_shape = X_train.shape[1],\n",
    "                             output_shape=NLABEL,\n",
    "                             ridge_penalty1=RIDGE1,\n",
    "                             dropout=DROPOUT,\n",
    "                             act_fun='relu',\n",
    "                             network_seed=NETWORK_SEED)\n",
    "    \n",
    "    loss_function = tf.keras.losses.CategoricalCrossentropy()    \n",
    "    model.compile(\n",
    "                  optimizer = tf.keras.optimizers.Adam(learning_rate=LR_INIT),\n",
    "                  loss = loss_function,\n",
    "                  metrics = [\n",
    "                      tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\", dtype=None),\n",
    "                      metrics.PredictionAccuracy(NLABEL)\n",
    "                      ]\n",
    "                  )           \n",
    "    return model, loss_function\n",
    "\n",
    "# #---------------------------------------------------\n",
    "# #LEARNING RATE CALLBACK FUNCTION\n",
    "# def scheduler(epoch, lr):\n",
    "#     # This function keeps the initial learning rate for the first ten epochs\n",
    "#     # and decreases it exponentially after that.\n",
    "#     if epoch < 10:\n",
    "#         return lr\n",
    "#     else:\n",
    "#         return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = 'exp_0/exp_000'\n",
    "\n",
    "\n",
    "ddir_X = '/Users/marcodia/Research/Data/global_daily_anomalies/'\n",
    "ddir_Y = '/Users/marcodia/Research/Data/processed_fields/precip_data/'\n",
    "ddir_out = '/Users/marcodia/Research/salinity_s2s/experiments/exp_0/exp_000/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = settings.get_settings(EXPERIMENT)\n",
    "\n",
    "PREDICTOR_VAR  = params['PREDICTOR_VAR']           \n",
    "PREDICTAND_VAR = params['PREDICTAND_VAR']              \n",
    "REGION_TOR     = params['REGION_TOR']          \n",
    "REGION_TAND    = params['REGION_TAND']            \n",
    "training_ens   = params['training_ens']            \n",
    "validation_ens = params['validation_ens']           \n",
    "testing_ens    = params['testing_ens']           \n",
    "train_list     = params['train_list']           \n",
    "lead           = params['lead']            \n",
    "days_average   = params['days_average']            \n",
    "GLOBAL_SEED    = params['GLOBAL_SEED']            \n",
    "HIDDENS        = params['HIDDENS']          \n",
    "DROPOUT        = params['DROPOUT']            \n",
    "RIDGE1         = params['RIDGE1']                    \n",
    "LR_INIT        = params['LR_INIT']\n",
    "BATCH_SIZE     = params['BATCH_SIZE']           \n",
    "RANDOM_SEED    = params['RANDOM_SEED']            \n",
    "act_fun        = params['act_fun']            \n",
    "N_EPOCHS       = params['N_EPOCHS']           \n",
    "PATIENCE       = params['PATIENCE']   \n",
    "window_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#>>>>>SET UP <<<<<<<<<<<<<<<\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "random.seed(GLOBAL_SEED)\n",
    "tf.compat.v1.random.set_random_seed(GLOBAL_SEED)\n",
    "\n",
    "NLABEL = 2\n",
    "\n",
    "YEARS = '1850-1949'\n",
    "STRT = pd.to_datetime('05-01-1850')\n",
    "END   = pd.to_datetime('08-31-1949')  + dt.timedelta(days=1)\n",
    "\n",
    "time_range = xr.cftime_range(str(STRT)[:10], str(END)[:10],calendar = 'noleap') #[0:10] corresponds to full datestamp\n",
    "time_range_szn = time_range.where(fnc.is_mjja(time_range.month)).dropna()\n",
    "TIME_X = xr.DataArray(time_range_szn + dt.timedelta(days=0), dims=['time'])     \n",
    "TIME_Y = xr.DataArray(time_range_szn + dt.timedelta(days=lead+days_average), dims=['time'])  #below comment explains time segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- X TRAINING ------\n",
    "count = 0 \n",
    "for i in train_list:\n",
    "    X_finame = PREDICTOR_VAR+'_'+REGION_TOR+'_'+YEARS+'_'+'ens'+i+'_dailyanom_detrend.nc'\n",
    "    X_all_full = xr.open_dataarray(ddir_X+X_finame)\n",
    "    X = X_all_full.where(X_all_full.time == TIME_X, drop=True)\n",
    "    \n",
    "    X_nptime = np.array(X.time)                 #for some annoying reason, it needed to be converted to numpy for creating DataArray   \n",
    "    X_nplat = np.array(X.lat)\n",
    "    X_nplon = np.array(X.lon)\n",
    "    del X_all_full \n",
    "\n",
    "    if count == 0: # don't rewrite empty matrix each time \n",
    "        X_all = xr.DataArray(np.zeros((len(train_list),X.shape[0],X.shape[1],X.shape[2]))+np.nan,\n",
    "                             dims = ['ens','time','lat','lon'],\n",
    "                             coords = [('ens',np.arange(0,len(train_list))),('time', X_nptime),('lat',X_nplat),('lon',X_nplon)])\n",
    "\n",
    "    X_all[count,:,:,:] = X   \n",
    "    \n",
    "    count = count+1\n",
    "    del X\n",
    "    \n",
    "Xtrain = X_all.stack(time_all=('ens','time')) # lat,lon,time*8 (8= number of training ens members) \n",
    "Xtrain = Xtrain.transpose('time_all','lat','lon') # time*8,lat,lon\n",
    "\n",
    "Xtrain_std = np.std(Xtrain,axis=0)\n",
    "Xtrain_mean = np.mean(Xtrain,axis=0)\n",
    "Xtrain = (Xtrain-Xtrain_mean)/Xtrain_std\n",
    "X_train = Xtrain.stack(z=('lat','lon'))\n",
    "\n",
    "# ---------- X VALIDATION----------\n",
    "X_finame  = PREDICTOR_VAR+'_'+REGION_TOR+'_'+YEARS+'_'+'ens'+str(validation_ens)+'_dailyanom_detrend.nc'\n",
    "Xval = xr.open_dataarray(ddir_X+X_finame)\n",
    "\n",
    "Xval= Xval.where(Xval.time == TIME_X, drop=True)\n",
    "Xval_unstack = (Xval - Xtrain_mean)/Xtrain_std\n",
    "\n",
    "Xval = Xval_unstack.stack(z=('lat','lon'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xval_unstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.dropna(dim='z', how = 'any')\n",
    "X_val = Xval.dropna(dim='z', how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% ----- Y TRAINING--------\n",
    "#Ytrain = np.zeros((len(Xval.time),NLABEL))\n",
    "#Ytrain_class  = np.zeros(len(Xval.time))\n",
    "count = 0\n",
    "for i in train_list:\n",
    "    Ytrain_finame = PREDICTAND_VAR+'_'+REGION_TAND+'_'+YEARS+'_ens'+str(i)+'_'+str(window_size)+'daysum.nc'\n",
    "\n",
    "    Y_all_full = xr.open_dataarray(ddir_Y+Ytrain_finame)\n",
    "    Y = Y_all_full.where(Y_all_full.time == TIME_Y, drop=True)\n",
    "\n",
    "    Y_nptime = np.array(Y.time)                 \n",
    "    del Y_all_full \n",
    "\n",
    "    if count == 0: # don't rewrite empty matrix each time \n",
    "        Y_all = xr.DataArray(np.zeros((len(train_list),Y.shape[0]))+np.nan,\n",
    "                             dims = ['ens','time'],\n",
    "                             coords = [('ens',np.arange(0,len(train_list))),('time', Y_nptime)])\n",
    "        \n",
    "        \n",
    "    Y_all[count,:] = Y   \n",
    "    count = count + 1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_use = Y_all.stack(time_all=('ens','time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_val = np.percentile(Y_use, 80)\n",
    "#mod_val   = np.percentile(Y_use,80)\n",
    "Ytrain_class = (Y_use >= light_val).astype(int) #+ (Y_use >= mod_val).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ytrain = (np.array(output_class).reshape(-1,1) == np.unique(output_class)).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How often does our data fall into each category? This is just for the last ensemble member in training\n",
    "calcpercent = lambda cat: str((np.sum(np.array(Ytrain_class) == cat)/len(Ytrain_class)*100).astype(int))\n",
    "\n",
    "# Print out the sizes of each class\n",
    "print('Frequency for each Precip Category')\n",
    "print('Light: ' + calcpercent(0) + '%')\n",
    "print('Heavy: ' + calcpercent(1) + '%')\n",
    "#print('Heavy: ' + calcpercent(2) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Distribution of precip concentrations\n",
    "\n",
    "# fig, axs = plt.subplots(2, 4, figsize = (15,8))\n",
    "\n",
    "# for m in np.arange(0,8):\n",
    "#     ax = axs[m//4,m%4]\n",
    "# #    sb.displot(Y_all[m,:], kind='hist')\n",
    "#     sb.histplot(Y_all[m,:], color='black', ax=ax)\n",
    "#     ax.set(xticks=(np.arange(0,55,step=5)))\n",
    "\n",
    "#     ax.set_xlabel('mm')\n",
    "#     Y_use = Y_all[m,:]\n",
    "#     light_val = np.percentile(Y_use, 40)\n",
    "#     mod_val   = np.percentile(Y_use,80)\n",
    "    \n",
    "#     ax.axvline(x=light_val, color='goldenrod')\n",
    "#     ax.axvline(x=mod_val, color='red')\n",
    "#     ax.set_title('Training Ensemble Member '+str(m+1))\n",
    "#     ax.text(8, 50, 'Light', rotation=90, color='goldenrod')\n",
    "#     ax.text(16, 50, 'Moderate', rotation=90, color='red')\n",
    "\n",
    "# fig.tight_layout(pad=1.0)\n",
    "# print('Histograms of Midwest Summer Precip 5-day Sums')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Y VALIDATION --------\n",
    "Yval_finame = PREDICTAND_VAR+'_'+REGION_TAND+'_'+YEARS+'_ens'+str(validation_ens)+'_'+str(window_size)+'daysum.nc'\n",
    "\n",
    "Y_all_full = xr.open_dataarray(ddir_Y+Yval_finame)\n",
    "Y = Y_all_full.where(Y_all_full.time == TIME_Y, drop=True)\n",
    "\n",
    "light_val = np.percentile(Y, 80)\n",
    "#mod_val   = np.percentile(Y,80)\n",
    "Yval_class = (Y >= light_val).astype(int) #+ (Y >= mod_val).astype(int)\n",
    "Yval = (np.array(Yval_class).reshape(-1,1) == np.unique(Yval_class)).astype(int)\n",
    "\n",
    "calcpercent = lambda cat: str((np.sum(np.array(Yval_class) == cat)/len(Yval_class)*100).astype(int))\n",
    "\n",
    "# Print out the sizes of each class\n",
    "print('Frequency for each Ozone Category')\n",
    "print('Light: ' + calcpercent(0) + '%')\n",
    "print('Heavy: ' + calcpercent(1) + '%')\n",
    "#print('Heavy: ' + calcpercent(2) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# over_sampler = RandomOverSampler(random_state=42)\n",
    "# X_bal, Y_bal = over_sampler.fit_resample(X_train, Ytrain_class)\n",
    "# print(f\"Training target statistics: {Counter(Y_bal)}\")\n",
    "# #print(f\"Validation target statistics: {Counter(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How often does our data fall into each category? This is just for the last ensemble member in training\n",
    "# calcpercent = lambda cat: str((np.sum(np.array(Y_bal) == cat)/len(Y_bal)*100).astype(int))\n",
    "\n",
    "# # Print out the sizes of each class\n",
    "# print('Frequency for each Category')\n",
    "# print('Light: ' + calcpercent(0) + '%')\n",
    "\n",
    "# print('Moderate: ' + calcpercent(1) + '%')\n",
    "# print('Heavy: ' + calcpercent(2) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here we can change how much the loss function takes into consideration different classes\n",
    "# CLASS_WEIGHT = {0 : 1 / np.mean(Ytrain[:,0] == 1),\n",
    "#                 1 : 1 / np.mean(Ytrain[:,1] == 1),\n",
    "#                 2 : 1 / np.mean(Ytrain[:,2] == 1)}\n",
    "\n",
    "CLASS_WEIGHT = {0 : 1, 1 : 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Make one hot vector -----\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "onehotlabels      = enc.fit_transform(np.array(Ytrain_class).reshape(-1, 1)).toarray()\n",
    "onehotlabels_val  = enc.fit_transform(np.array(Yval_class).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotlabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotlabels_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddir_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = [0.0, 0.1, 0.3, 0.7]\n",
    "ridge = [0.0, 0.1, 0.5, 1.0]\n",
    "batch = [64]\n",
    "HIDDENS = [64,32]\n",
    "RANDOM_SEED = [98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- TRAIN NN --------------------\n",
    "for NETWORK_SEED in RANDOM_SEED:\n",
    "    for DROPOUT in dropout:\n",
    "        for RIDGE1 in ridge:\n",
    "            for BATCH_SIZE in batch:\n",
    "                print(NETWORK_SEED)\n",
    "\n",
    "                # the network seed changes the random seed for the initialized weights.\n",
    "                # this means that a different network seed can give a different result (e.g. it finds a different minimum in the loss)\n",
    "                # ----- MAKE NN -----\n",
    "                es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',     #monitor='val_prediction_accuracy'\n",
    "                                                               patience=PATIENCE,\n",
    "                                                               mode='auto',\n",
    "                                                               restore_best_weights=True,\n",
    "                                                               verbose=1)\n",
    "                #lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose=0) #I don't use in this study \n",
    "                #callbacks = [es_callback,lr_callback]\n",
    "                callbacks = [es_callback]\n",
    "\n",
    "                model, loss_function = make_model()\n",
    "\n",
    "                hotlabels = onehotlabels[:,:model.output_shape[-1]]\n",
    "                hotlabels_val = onehotlabels_val[:,:model.output_shape[-1]]\n",
    "\n",
    "                # ----- TRAINING NETWORK -----\n",
    "                start_time = time.time()\n",
    "                history = model.fit(X_train,\n",
    "                                    hotlabels,\n",
    "                                    validation_data=(X_val, hotlabels_val),\n",
    "                                    class_weight = CLASS_WEIGHT,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    epochs=N_EPOCHS,\n",
    "                                    shuffle=True,\n",
    "                                    verbose=0,\n",
    "                                    callbacks=callbacks,\n",
    "                                   )\n",
    "                stop_time = time.time()\n",
    "                tf.print(f\"Elapsed time during fit = {stop_time - start_time:.2f} seconds\\n\")\n",
    "\n",
    "                # ----- SAVE MODEL -----\n",
    "                fi = '_operationalseed'+str(NETWORK_SEED)+str(DROPOUT)+str(RIDGE1)+str(BATCH_SIZE)+'.h5' \n",
    "                model.save_weights(ddir_out+fi)\n",
    "\n",
    "                # ----- PLOT THE RESULTS -----\n",
    "                plot.plot_results(\n",
    "                    history,\n",
    "                    exp_info=(N_EPOCHS, HIDDENS, LR_INIT, BATCH_SIZE, NETWORK_SEED, PATIENCE, RIDGE1, DROPOUT, CLASS_WEIGHT),\n",
    "                    showplot=True\n",
    "                )\n",
    "\n",
    "                # ----- PRINT THE RESULTS -----\n",
    "                predictions = np.argmax(model.predict(X_val),axis=-1)\n",
    "                predictions_training = np.argmax(model.predict(X_train),axis=-1)\n",
    "                confusion_training = tf.math.confusion_matrix(labels=Ytrain_class, predictions=predictions_training)\n",
    "                confusion = tf.math.confusion_matrix(labels=Yval_class, predictions=predictions)\n",
    "                zero_precision  = (np.sum(confusion[0,0])/np.sum(confusion[:,0])) * 100\n",
    "                one_precision   = (np.sum(confusion[1,1])/np.sum(confusion[:,1])) * 100\n",
    "                #two_precision   = (np.sum(confusion[2,2])/np.sum(confusion[:,2])) * 100\n",
    "\n",
    "                # Number of times network predicts a given class\n",
    "                zero_predictions  = (np.shape(np.where(predictions==0))[1]/predictions.shape[0])* 100\n",
    "                one_predictions   = (np.shape(np.where(predictions==1))[1]/predictions.shape[0])* 100\n",
    "                #two_predictions   = (np.shape(np.where(predictions==2))[1]/predictions.shape[0])* 100\n",
    "\n",
    "                print('Zero prediction accuracy: '+str(zero_precision)[:2]+'%')\n",
    "                print('Zero: '+str(zero_predictions)[:3]+'% of predictions')\n",
    "                print('One prediction accuracy: '+str(one_precision)[:2]+'%')\n",
    "                print('One: '+str(one_predictions)[:3]+'% of predictions')\n",
    "            #     print('Two prediction accuracy: '+str(two_precision)[:2]+'%')\n",
    "            #     print('Two: '+str(two_predictions)[:3]+'% of predictions')\n",
    "\n",
    "                print('Validation Loss at Best Epoch: '+str(es_callback.best*1))#+'%')\n",
    "\n",
    "                # ----- END LOOP -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- PRINT THE RESULTS -----\n",
    "predictions = np.argmax(model.predict(X_val),axis=-1)\n",
    "predictions_training = np.argmax(model.predict(X_train),axis=-1)\n",
    "confusion_training = tf.math.confusion_matrix(labels=Ytrain_class, predictions=predictions_training)\n",
    "confusion = tf.math.confusion_matrix(labels=Yval_class, predictions=predictions)\n",
    "zero_precision  = (np.sum(confusion[0,0])/np.sum(confusion[:,0])) * 100\n",
    "one_precision   = (np.sum(confusion[1,1])/np.sum(confusion[:,1])) * 100\n",
    "#two_precision   = (np.sum(confusion[2,2])/np.sum(confusion[:,2])) * 100\n",
    "\n",
    "# Number of times network predicts a given class\n",
    "zero_predictions  = (np.shape(np.where(predictions==0))[1]/predictions.shape[0])* 100\n",
    "one_predictions   = (np.shape(np.where(predictions==1))[1]/predictions.shape[0])* 100\n",
    "#two_predictions   = (np.shape(np.where(predictions==2))[1]/predictions.shape[0])* 100\n",
    "\n",
    "print('Zero prediction accuracy: '+str(zero_precision)[:2]+'%')\n",
    "print('Zero: '+str(zero_predictions)[:3]+'% of predictions')\n",
    "print('One prediction accuracy: '+str(one_precision)[:2]+'%')\n",
    "print('One: '+str(one_predictions)[:3]+'% of predictions')\n",
    "# print('Two prediction accuracy: '+str(two_precision)[:2]+'%')\n",
    "# print('Two: '+str(two_predictions)[:3]+'% of predictions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What predictions did the model make for our training, validation, and test sets?\n",
    "Ptrain = model.predict(X_train) # Array of class likelihoods for each class\n",
    "Pval = model.predict(X_val)\n",
    "\n",
    "Cptrain = Ptrain.argmax(axis=1) # 1-D array of predicted class (highest likelihood)\n",
    "Cpval = Pval.argmax(axis=1)\n",
    "\n",
    "Cttrain = onehotlabels.argmax(axis=1) # 1-D array of truth class\n",
    "Ctval = onehotlabels_val.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "print('Validation Categorical Accuracy:', accuracy_score(Ctval, Cpval) )\n",
    "\n",
    "# Weight equal to the inverse of the frequency of the class\n",
    "cat_weights = np.sum((1 / np.mean(X_train, axis=0)) * X_val, axis=0) \n",
    "print('Validation Weighted Categorical Accuracy:', accuracy_score(Ctval, Cpval, sample_weight=cat_weights) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(predclasses, targclasses):\n",
    "\n",
    "    class_names = np.unique(targclasses)\n",
    "\n",
    "    table = []\n",
    "    for pred_class in class_names:\n",
    "        row = []\n",
    "        for true_class in class_names:\n",
    "            row.append(100 * np.mean(predclasses[targclasses == true_class] == pred_class))\n",
    "        table.append(row)\n",
    "    class_titles_t = [\"T(Light)\", \"T(Moderate)\", \"T(Heavy)\"]\n",
    "    class_titles_p = [\"P(Light)\", \"P(Moderate)\", \"P(Heavy)\"]\n",
    "    conf_matrix = pd.DataFrame(table, index=class_titles_p, columns=class_titles_t)\n",
    "    display(conf_matrix.style.background_gradient(cmap='Blues').format(\"{:.1f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What predictions did the model make for our training, validation, and test sets?\n",
    "Ptrain = model.predict(X_train) # Array of class likelihoods for each class\n",
    "Pval = model.predict(X_val)\n",
    "\n",
    "Cptrain = Ptrain.argmax(axis=1) # 1-D array of predicted class (highest likelihood)\n",
    "Cpval = Pval.argmax(axis=1)     #argmax along axis=1 returns the index which has the highest value for each row \n",
    "\n",
    "Cttrain = hotlabels.argmax(axis=1) # 1-D array of truth class\n",
    "Ctval = hotlabels_val.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted versus Target Classes\")\n",
    "print(\"\")\n",
    "print(\"Training\")\n",
    "confusion_matrix(Cptrain, Cttrain)\n",
    "print(\"Validation\")\n",
    "confusion_matrix(Cpval, Ctval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(model.predict(X_val),axis=-1)\n",
    "confusion = tf.math.confusion_matrix(labels=Yval_class, predictions=predictions)\n",
    "sns.heatmap(confusion,annot=True,cmap=plt.cm.Reds, alpha=0.5, fmt ='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.savefig(ddir_out+'confusion_matrix_lastseed.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
